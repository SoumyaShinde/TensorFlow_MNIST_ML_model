{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08e4d0c3-c725-41bc-8e31-2daf21c443db",
   "metadata": {},
   "source": [
    "<h2>Loading the data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "id": "56ba5985224dc8",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "import tensorflow as tf"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa38b36067da620",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mnist dataset is used as it contains images and handwritten digits\n",
    "#tensorflow makes it easy to load this dataset with just few lines of code\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ca9c64-3e5d-4e60-825e-f3e29d418290",
   "metadata": {},
   "source": [
    "<h2>Preprocessing the data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52695876-5c94-43f0-af1b-9b7cd9f07288",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we will normalize the pixel values to be b/w 0 and 1, default it s b/w 1 and 255\n",
    "#divinding them by 255 makes them lie b/w 0 adn 1\n",
    "\n",
    "#Neural ntwk perform more efficient when input data is normalized to a consistant range.\n",
    "x_train, x_test = x_train / 255.0 , x_test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5639bf1b-d54f-4f5a-a06e-488617591f23",
   "metadata": {},
   "source": [
    "<h2> building the model</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc3d267d-90e0-4a4f-93bc-a657d0a5acfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/soumyashinde/Library/Python/3.9/lib/python/site-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "#Simple neural ntwk is used for this task\n",
    "#Tensorflow's Keras API makes it straightforward to define the model\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "#We start by FLATENNING, to convert 2D images to 1D vector\n",
    "#Dense with 128 neurons and ReLU activation function is added\n",
    "#Dropout layer to prevent overfitting\n",
    "#another Dense layer with 10 neurons, corresponding to 10 digit classes classification from 0 through 9\n",
    "# softmax activartion function to output probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96e481a-8df3-426e-a6dc-f79d816c3463",
   "metadata": {},
   "source": [
    "<h2>Compiling the model</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23858270-561c-4278-90d8-68eed503928e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this step involves specifiying the optimizer, loss function and evaluation matrics\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "#adam optimizer is used for efficient training\n",
    "#sparse_categorical_cross entropy as loss functn because we're dealing with multiclass classfication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b441474d-b962-4fbd-a5c2-8327faf5f86d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 496us/step - accuracy: 0.8560 - loss: 0.4848\n",
      "Epoch 2/5\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 485us/step - accuracy: 0.9543 - loss: 0.1559\n",
      "Epoch 3/5\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 569us/step - accuracy: 0.9665 - loss: 0.1117\n",
      "Epoch 4/5\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 486us/step - accuracy: 0.9720 - loss: 0.0887\n",
      "Epoch 5/5\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 495us/step - accuracy: 0.9763 - loss: 0.0750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x13042fdc0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#epocs is 5 meaning the model will see the training dataset 5 times\n",
    "model.fit(x_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398256e8-9b3b-40f4-a582-02fc4e969387",
   "metadata": {},
   "source": [
    "<h2> Test the model</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6e20f97-73c7-4e37-9349-91291f04c0bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 0s - 402us/step - accuracy: 0.9775 - loss: 0.0756\n",
      "Test accuracy: 0.9775000214576721\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(f'Test accuracy: {test_acc}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf924b5c-9ed9-42cf-9986-b67f3d7edb76",
   "metadata": {},
   "source": [
    "<h2> Saving the model</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ffda1d3-590c-4be0-b421-ff6bf2a060d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tensorflow makes it easy with save method\n",
    "model.save('my_mnist_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8101a168-5a16-4b25-8d49-f8cc84f7e142",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = tf.keras.models.load_model('my_mnist_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74523374-69a7-4bb4-bdb1-5ff5404ba984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Sequential name=sequential, built=True>\n"
     ]
    }
   ],
   "source": [
    "print(loaded_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f24cf8f4-79c6-4fc3-9f75-2b8cd81c590d",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#The above is a complete implementation of a ML model using TensorFlow"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
